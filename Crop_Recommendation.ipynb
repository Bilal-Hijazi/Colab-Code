{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMG9+0d9sQ9drfkbAQhqecG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bilal-Hijazi/Colab-Code/blob/main/Crop_Recommendation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we are trying to predict multiple values (not binary classification), to simplify the problem we try to predict if the enviroment is suitable for rice (1) or no (0) (maybe consinder other crops)"
      ],
      "metadata": {
        "id": "-D0Wlcag6c0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"Crop_recommendation.csv\")\n",
        "\n",
        "# Change label column values to 1 if value is 'rice' and 0 otherwise\n",
        "data['label'] = data['label'].replace({'rice': 1, 'maize': 0, 'chickpea': 0, 'kidneybeans': 0, 'pigeonpeas': 0, 'mothbeans': 0, 'mungbean': 0, 'blackgram': 0, 'lentil': 0, 'pomegranate': 0, 'banana': 0, 'mango': 0, 'grapes': 0, 'watermelon': 0, 'muskmelon': 0, 'apple': 0, 'orange': 0, 'papaya': 0, 'coconut': 0, 'cotton': 0, 'jute': 0, 'coffee': 0, 'mushroom': 0})\n",
        "\n",
        "# Convert other columns from numerical values to binary values using the average as the threshold\n",
        "for col in data.columns[data.columns != 'label']:\n",
        "    # Calculate the average for each column\n",
        "    avg = data[col].mean()\n",
        "    # Convert numerical values to binary based on the average\n",
        "    data[col] = (data[col] > avg).astype(int)\n",
        "\n",
        "\n",
        "X = data.drop(\"label\",axis=1)\n",
        "y = data[\"label\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "results = {}\n",
        "\n",
        "# For each r, create an imbalanced dataset, train, and record precision and recall\n",
        "# Classifier used: decision tree\n",
        "for r in np.arange(0.9, 0, -0.1):\n",
        "    # Selecting fraction r of positive class instances\n",
        "    positive_indices = np.where(y_train == 1)[0]\n",
        "    np.random.shuffle(positive_indices)\n",
        "    selected_positive_indices = positive_indices[:int(r * len(positive_indices))]\n",
        "    negative_indices = np.where(y_train == 0)[0]\n",
        "\n",
        "    # Creating imbalanced training dataset\n",
        "    imbalanced_train_indices = np.concatenate((selected_positive_indices, negative_indices))\n",
        "    X_train_imbalanced = X_train.iloc[imbalanced_train_indices]\n",
        "    y_train_imbalanced = y_train.iloc[imbalanced_train_indices]\n",
        "\n",
        "    # Training the Random Forest Classifier\n",
        "    clf = RandomForestClassifier(random_state=42)\n",
        "    clf.fit(X_train_imbalanced, y_train_imbalanced)\n",
        "    # Predictions and recording precision, recall, and F1 score\n",
        "    y_pred = clf.predict(X_test)\n",
        "    precision = precision_score(y_test, y_pred,zero_division = 0)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    results[round(r, 1)] = {'Precision': round(precision, 3), 'Recall': round(recall, 3), 'F1 Score': round(f1, 3)}\n",
        "\n",
        "# Print the results\n",
        "\n",
        "pd.DataFrame(results)\n"
      ],
      "metadata": {
        "id": "6wCGkrrbTff1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "data = pd.read_csv(\"Crop_recommendation.csv\")\n",
        "\n",
        "# Change label column values to 1 if value is 'rice' and 0 otherwise\n",
        "data['label'] = data['label'].replace({'rice': 1, 'maize': 0, 'chickpea': 0, 'kidneybeans': 0, 'pigeonpeas': 0, 'mothbeans': 0, 'mungbean': 0, 'blackgram': 0, 'lentil': 0, 'pomegranate': 0, 'banana': 0, 'mango': 0, 'grapes': 0, 'watermelon': 0, 'muskmelon': 0, 'apple': 0, 'orange': 0, 'papaya': 0, 'coconut': 0, 'cotton': 0, 'jute': 0, 'coffee': 0, 'mushroom': 0})\n",
        "\n",
        "# Convert other columns from numerical values to binary values using the average as the threshold\n",
        "for col in data.columns[data.columns != 'label']:\n",
        "    # Calculate the average for each column\n",
        "    avg = data[col].mean()\n",
        "    # Convert numerical values to binary based on the average\n",
        "    data[col] = (data[col] > avg).astype(int)\n",
        "\n",
        "\n",
        "X = data.drop(\"label\",axis=1)\n",
        "y = data[\"label\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "results = {}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for r in np.arange(0.9, 0, -0.1):\n",
        "    # Selecting fraction r of positive class instances\n",
        "    positive_indices = np.where(y_train == 1)[0]\n",
        "    np.random.shuffle(positive_indices)\n",
        "    selected_positive_indices = positive_indices[:int(r * len(positive_indices))]\n",
        "    negative_indices = np.where(y_train == 0)[0]\n",
        "\n",
        "    # Creating imbalanced training dataset\n",
        "    imbalanced_train_indices = np.concatenate((selected_positive_indices, negative_indices))\n",
        "    X_train_imbalanced = X_train.iloc[imbalanced_train_indices]\n",
        "    y_train_imbalanced = y_train.iloc[imbalanced_train_indices]\n",
        "\n",
        "    # Training The XGB Classifier\n",
        "    xgb = XGBClassifier()\n",
        "    xgb.fit(X_train_imbalanced, y_train_imbalanced)\n",
        "    # Predictions and recording precision, recall, and F1 score\n",
        "    y_pred = xgb.predict(X_test)\n",
        "    precision = precision_score(y_test, y_pred, zero_division = 0)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    results[round(r, 1)] = {'Precision': round(precision, 3), 'Recall': round(recall, 3), 'F1 Score': round(f1, 3)}\n",
        "\n",
        "# Print the results\n",
        "pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "T19ypGttWSBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data = pd.read_csv(\"Crop_recommendation.csv\")\n",
        "\n",
        "# Change label column values to 1 if value is 'rice' and 0 otherwise\n",
        "data['label'] = data['label'].replace({'rice': 1, 'maize': 0, 'chickpea': 0, 'kidneybeans': 0, 'pigeonpeas': 0, 'mothbeans': 0, 'mungbean': 0, 'blackgram': 0, 'lentil': 0, 'pomegranate': 0, 'banana': 0, 'mango': 0, 'grapes': 0, 'watermelon': 0, 'muskmelon': 0, 'apple': 0, 'orange': 0, 'papaya': 0, 'coconut': 0, 'cotton': 0, 'jute': 0, 'coffee': 0, 'mushroom': 0})\n",
        "\n",
        "# Convert other columns from numerical values to binary values using the average as the threshold\n",
        "for col in data.columns[data.columns != 'label']:\n",
        "    # Calculate the average for each column\n",
        "    avg = data[col].mean()\n",
        "    # Convert numerical values to binary based on the average\n",
        "    data[col] = (data[col] > avg).astype(int)\n",
        "\n",
        "\n",
        "X = data.drop(\"label\",axis=1)\n",
        "y = data[\"label\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "results = {}\n",
        "\n",
        "\n",
        "\n",
        "for r in np.arange(0.9, 0, -0.1):\n",
        "    # Selecting fraction r of positive class instances\n",
        "    positive_indices = np.where(y_train == 1)[0]\n",
        "    np.random.shuffle(positive_indices)\n",
        "    selected_positive_indices = positive_indices[:int(r * len(positive_indices))]\n",
        "    negative_indices = np.where(y_train == 0)[0]\n",
        "\n",
        "    # Creating imbalanced training dataset\n",
        "    imbalanced_train_indices = np.concatenate((selected_positive_indices, negative_indices))\n",
        "    X_train_imbalanced = X_train.iloc[imbalanced_train_indices]\n",
        "    y_train_imbalanced = y_train.iloc[imbalanced_train_indices]\n",
        "\n",
        "    # Training The SVM Classifier\n",
        "    svmClassifier = svm.LinearSVC(random_state=42)  # Instantiate SVM classifier\n",
        "    svmClassifier.fit(X_train_imbalanced, y_train_imbalanced)  # Train the SVM classifier\n",
        "\n",
        "    # Predictions and recording precision, recall, and F1 score\n",
        "    y_pred = svmClassifier.predict(X_test)\n",
        "    precision = precision_score(y_test, y_pred,zero_division = 0)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    results[round(r, 1)] = {'Precision': round(precision, 3), 'Recall': round(recall, 3), 'F1 Score': round(f1, 3)}\n",
        "\n",
        "# Print the results\n",
        "print(pd.DataFrame(results))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wab3fyytWhwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "data = pd.read_csv(\"Crop_recommendation.csv\")\n",
        "\n",
        "# Change label column values to 1 if value is 'rice' and 0 otherwise\n",
        "data['label'] = data['label'].replace({'rice': 1, 'maize': 0, 'chickpea': 0, 'kidneybeans': 0, 'pigeonpeas': 0, 'mothbeans': 0, 'mungbean': 0, 'blackgram': 0, 'lentil': 0, 'pomegranate': 0, 'banana': 0, 'mango': 0, 'grapes': 0, 'watermelon': 0, 'muskmelon': 0, 'apple': 0, 'orange': 0, 'papaya': 0, 'coconut': 0, 'cotton': 0, 'jute': 0, 'coffee': 0, 'mushroom': 0})\n",
        "\n",
        "# Convert other columns from numerical values to binary values using the average as the threshold\n",
        "for col in data.columns[data.columns != 'label']:\n",
        "    # Calculate the average for each column\n",
        "    avg = data[col].mean()\n",
        "    # Convert numerical values to binary based on the average\n",
        "    data[col] = (data[col] > avg).astype(int)\n",
        "\n",
        "\n",
        "X = data.drop(\"label\",axis=1)\n",
        "y = data[\"label\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "results = {}\n",
        "\n",
        "\n",
        "\n",
        "for r in np.arange(0.9, 0, -0.1):\n",
        "\n",
        "    positive_indices = np.where(y_train == 1)[0]\n",
        "    np.random.shuffle(positive_indices)\n",
        "    selected_positive_indices = positive_indices[:int(r * len(positive_indices))]\n",
        "    negative_indices = np.where(y_train == 0)[0]\n",
        "\n",
        "\n",
        "    imbalanced_train_indices = np.concatenate((selected_positive_indices, negative_indices))\n",
        "    X_train_imbalanced = X_train.iloc[imbalanced_train_indices]\n",
        "    y_train_imbalanced = y_train.iloc[imbalanced_train_indices]\n",
        "\n",
        "\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train_imbalanced.shape[1],)),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train_imbalanced, y_train_imbalanced, epochs=10, batch_size=32, verbose=0)\n",
        "\n",
        "    # Predictions and recording precision, recall, and F1 score\n",
        "    y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "    precision = precision_score(y_test, y_pred, zero_division = 0)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    results[round(r, 1)] = {'Precision': round(precision, 3), 'Recall': round(recall, 3), 'F1 Score': round(f1, 3)}\n",
        "\n",
        "# Print the results\n",
        "print(pd.DataFrame(results))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VgRNIduSXATf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "data = pd.read_csv(\"Crop_recommendation.csv\")\n",
        "\n",
        "# Change label column values to 1 if value is 'rice' and 0 otherwise\n",
        "data['label'] = data['label'].replace({'rice': 1, 'maize': 0, 'chickpea': 0, 'kidneybeans': 0, 'pigeonpeas': 0, 'mothbeans': 0, 'mungbean': 0, 'blackgram': 0, 'lentil': 0, 'pomegranate': 0, 'banana': 0, 'mango': 0, 'grapes': 0, 'watermelon': 0, 'muskmelon': 0, 'apple': 0, 'orange': 0, 'papaya': 0, 'coconut': 0, 'cotton': 0, 'jute': 0, 'coffee': 0, 'mushroom': 0})\n",
        "\n",
        "# Convert other columns from numerical values to binary values using the average as the threshold\n",
        "for col in data.columns[data.columns != 'label']:\n",
        "    # Calculate the average for each column\n",
        "    avg = data[col].mean()\n",
        "    # Convert numerical values to binary based on the average\n",
        "    data[col] = (data[col] > avg).astype(int)\n",
        "\n",
        "\n",
        "X = data.drop(\"label\",axis=1)\n",
        "y = data[\"label\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "results = {}\n",
        "\n",
        "\n",
        "for r in np.arange(0.9, 0, -0.1):\n",
        "    # Select fraction r of positive class instances\n",
        "    positive_indices = np.where(y_train == 1)[0]\n",
        "    np.random.shuffle(positive_indices)\n",
        "    selected_positive_indices = positive_indices[:int(r * len(positive_indices))]\n",
        "    negative_indices = np.where(y_train == 0)[0]\n",
        "\n",
        "    # Create imbalanced training dataset\n",
        "    imbalanced_train_indices = np.concatenate((selected_positive_indices, negative_indices))\n",
        "    X_train_imbalanced = X_train.iloc[imbalanced_train_indices]\n",
        "    y_train_imbalanced = y_train.iloc[imbalanced_train_indices]\n",
        "\n",
        "    # Initialize and train the MLPClassifier\n",
        "    mlp = MLPClassifier(random_state=42, max_iter=500)\n",
        "    mlp.fit(X_train_imbalanced, y_train_imbalanced)\n",
        "\n",
        "    # Predictions and recording precision, recall, and F1 score\n",
        "    y_pred = mlp.predict(X_test)\n",
        "    precision = precision_score(y_test, y_pred, zero_division = 0)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    results[round(r, 1)] = {'Precision': round(precision, 3), 'Recall': round(recall, 3), 'F1 Score': round(f1, 3)}\n",
        "\n",
        "# Print the results\n",
        "print(pd.DataFrame(results))\n"
      ],
      "metadata": {
        "id": "woKImeU4YSAQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}